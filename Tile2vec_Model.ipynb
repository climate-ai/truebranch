{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "To7wiixVnYer"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "from time import time\n",
    "from torch.autograd import Variable\n",
    "from PIL import Image\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "sys.path.append('/Users/Simona/tile2vec/src')\n",
    "import tilenet\n",
    "from tilenet import make_tilenet\n",
    "import resnet \n",
    "from resnet import ResNet18\n",
    "#from src.tilenet import make_tilenet\n",
    "#from src.resnet import ResNet18\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd '/Users/Simona/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Classifier_v4\n",
    "from Classifier_v4 import RF\n",
    "from Classifier_v4 import LR\n",
    "from Classifier_v4 import MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aIZnr_zAnYex"
   },
   "source": [
    "## Step 1. Loading pre-trained model\n",
    "In this step, we will initialize a new TileNet model and then load the pre-trained weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PYG8g8aRnYey"
   },
   "outputs": [],
   "source": [
    "# Setting up model\n",
    "in_channels = 4\n",
    "z_dim = 512\n",
    "cuda = torch.cuda.is_available()\n",
    "# tilenet = make_tilenet(in_channels=in_channels, z_dim=z_dim)\n",
    "# Use old model for now\n",
    "tilenet = ResNet18()\n",
    "if cuda: tilenet.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd tile2vec/models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "cPLEU673nYe1",
    "outputId": "c7c490ff-87f4-419b-a847-653aff4178b4",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load parameters\n",
    "model_fn = '../models/naip_trained.ckpt'\n",
    "print(model_fn)\n",
    "checkpoint = torch.load(model_fn,map_location=torch.device('cpu'))\n",
    "tilenet.load_state_dict(checkpoint)\n",
    "tilenet.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "d70M2GQ_nYe6"
   },
   "source": [
    "## Step 2. Embed NAIP tiles\n",
    "In this step, we'll use TileNet to embed the NAIP tiles provided in `tile2vec/data/tiles`. There are 1000 tiles in total, named `1tile.npy` through `1000tile.npy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pFp1Lqlvkufi"
   },
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "c5zewEChkxuM"
   },
   "outputs": [],
   "source": [
    "# Set the image transforms\n",
    "train_transform = transforms.Compose([transforms.Resize(100),\n",
    "                                    #transforms.RandomResizedCrop(scale=(0.16, 1), ratio=(0.75, 1.33), size=64),\n",
    "                                    #transforms.RandomHorizontalFlip(0.5),\n",
    "                                    transforms.ToTensor(),\n",
    "                                    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])\n",
    "\n",
    "val_transform = transforms.Compose([transforms.Resize(100),\n",
    "                                    transforms.ToTensor(),\n",
    "                                    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset =  datasets.ImageFolder('/Users/Simona/Fresno_Area/train', transform=train_transform)\n",
    "val_dataset =  datasets.ImageFolder('/Users/Simona/Fresno_Area/val', transform=val_transform)\n",
    "test_dataset =  datasets.ImageFolder('/Users/Simona/Fresno_Area/test', transform=val_transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2addObYVyVTy"
   },
   "source": [
    "# Train embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LG4U3BhigEWE"
   },
   "outputs": [],
   "source": [
    "# Embed tiles\n",
    "from torch.autograd import Variable\n",
    "n_tiles = len(train_dataset)\n",
    "z_dim = 512\n",
    "X_train = np.zeros((n_tiles, z_dim))\n",
    "for idx in range(n_tiles):\n",
    "    tile = train_dataset[idx][0]\n",
    "    tile = tile.numpy()\n",
    "    tile = np.concatenate((tile, np.zeros((1, 100, 100))), axis=0)\n",
    "    tile = np.expand_dims(tile, axis=0)\n",
    "    # Scale to [0, 1]\n",
    "    tile = tile / 255\n",
    "    # Embed tile\n",
    "    tile = torch.from_numpy(tile).float()\n",
    "    tile = Variable(tile)\n",
    "    z = tilenet.encode(tile)\n",
    "    z = z.data.numpy()\n",
    "    #print(z.shape)\n",
    "    X_train[idx,:] = z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('/Users/Simona/Fresno_Area/X_train_tile2vec',X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.loadtxt('/Users/Simona/Fresno_Area/X_train_tile2vec')\n",
    "X_test = np.loadtxt('/Users/Simona/Fresno_Area/X_test_tile2vec')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "doITxn6-yTDg"
   },
   "source": [
    "# Test embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "N85M4adKk51b"
   },
   "outputs": [],
   "source": [
    "# Embed tiles\n",
    "from torch.autograd import Variable\n",
    "n_tiles = len(test_dataset)\n",
    "z_dim = 512\n",
    "X_test = np.zeros((n_tiles, z_dim))\n",
    "for idx in range(n_tiles):\n",
    "    tile = test_dataset[idx][0]\n",
    "    tile = tile.numpy()\n",
    "    tile = np.concatenate((tile, np.zeros((1, 100, 100))), axis=0)\n",
    "    tile = np.expand_dims(tile, axis=0)\n",
    "    # Scale to [0, 1]\n",
    "    tile = tile / 255\n",
    "    # Embed tile\n",
    "    tile = torch.from_numpy(tile).float()\n",
    "    tile = Variable(tile)\n",
    "    z = tilenet.encode(tile)\n",
    "    z = z.data.numpy()\n",
    "    #print(z.shape)\n",
    "    X_test[idx,:] = z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('/Users/Simona/Fresno_Area/X_test_tile2vec',X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import numpy as np\n",
    "from numpy.linalg import norm\n",
    "import random\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "def build_pairs_training(train_emb):\n",
    "\n",
    "    train_pairs = train_emb.shape[0]\n",
    "    same = []\n",
    "    same_labels = []\n",
    "\n",
    "    for i in range(0,train_pairs,2):\n",
    "        #print(i,i+1)\n",
    "        same.append((train_emb[i],train_emb[i+1]))\n",
    "        same_labels.append(1)\n",
    "    #print(\"same\",len(same))\n",
    "\n",
    "    #naip even num, sen odd num\n",
    "    diff = []\n",
    "    diff_labels = []\n",
    "\n",
    "    for i in range(0,train_pairs,2):\n",
    "        j = random.randrange(1,(train_pairs-2),2)\n",
    "        if i != j and abs(i-j)>1:\n",
    "            #print(i,j)\n",
    "            diff.append((train_emb[i],train_emb[j]))\n",
    "            diff_labels.append(0)\n",
    "        else:\n",
    "            j +=2\n",
    "            #print(\"diff\",i,j)\n",
    "            diff.append((train_emb[i],train_emb[j]))\n",
    "            diff_labels.append(0)\n",
    "\n",
    "    train_emb= same+diff\n",
    "    train_lab = same_labels+diff_labels\n",
    "\n",
    "    train_emb  = np.asarray(train_emb)\n",
    "    train_lab   = np.asarray(train_lab)\n",
    "    indices = np.arange(train_emb.shape[0])\n",
    "    np.random.shuffle(indices)\n",
    "\n",
    "    train_emb  = train_emb[indices]\n",
    "    train_lab  = train_lab[indices]\n",
    "     \n",
    "    #print(train_emb.shape)\n",
    "    train_emb = train_emb.reshape(train_emb.shape[0],train_emb.shape[1]*train_emb.shape[2])\n",
    "    #print(train_emb.shape)\n",
    "    #train_emb = train_emb.reshape(-1, 1)\n",
    "    #train_emb = train_emb.reshape(-1, 1)\n",
    "\n",
    "    return train_emb , train_lab\n",
    "\n",
    "def build_pairs_testing(test_emb):\n",
    "\n",
    "    same = []\n",
    "    same_labels = []\n",
    "\n",
    "    test_pairs = test_emb.shape[0]\n",
    "\n",
    "    for i in range(0,test_pairs,2):\n",
    "        same.append((test_emb[i],test_emb[i+1]))\n",
    "        same_labels.append(1)\n",
    "\n",
    "    #naip even num, sen odd num\n",
    "    diff = []\n",
    "    diff_labels = []\n",
    "\n",
    "    for i in range(0,test_pairs,2):\n",
    "        j = random.randrange(1,(test_pairs-2),2)\n",
    "        if i != j and abs(i-j)>1:\n",
    "            #print(i,j)\n",
    "            diff.append((test_emb[i],test_emb[j]))\n",
    "            diff_labels.append(0)\n",
    "        else:\n",
    "            j +=2\n",
    "            #print(\"diff\",i,j)\n",
    "            diff.append((test_emb[i],test_emb[j]))\n",
    "            diff_labels.append(0)\n",
    "\n",
    "    test_emb= same+diff\n",
    "    test_lab = same_labels+diff_labels\n",
    "\n",
    "    test_emb = np.asarray(test_emb)\n",
    "    test_lab  = np.asarray(test_lab)\n",
    "    indices = np.arange(test_emb.shape[0])\n",
    "    np.random.shuffle(indices)\n",
    "\n",
    "    test_emb = test_emb[indices]\n",
    "    test_lab = test_lab[indices]\n",
    "    \n",
    "    test_emb = test_emb.reshape(test_emb.shape[0],test_emb.shape[1]*test_emb.shape[2])\n",
    "\n",
    "    #test_emb = test_emb.reshape(-1, 1)\n",
    "    #test_emb=  test_emb.reshape(-1, 1)\n",
    "\n",
    "    return test_emb, test_lab\n",
    "\n",
    "def RF(X_train,X_test,n_trials = 100):\n",
    "    accs = np.zeros((n_trials,))\n",
    "\n",
    "    for i in range(n_trials):\n",
    "        # Splitting data and training RF classifer\n",
    "        X_tr, y_tr = build_pairs_training(X_train)\n",
    "        X_te, y_te =  build_pairs_testing(X_test)\n",
    "        rf = RandomForestClassifier()\n",
    "        rf.fit(X_tr, y_tr)\n",
    "        accs[i] = rf.score(X_te, y_te)\n",
    "    print('Mean accuracy: {:0.4f}'.format(accs.mean()))\n",
    "    print('Standard deviation: {:0.4f}'.format(accs.std()))\n",
    "\n",
    "def LR(X_train,X_test,n_trials = 100):\n",
    "      accs = np.zeros((n_trials,))\n",
    "      for i in range(n_trials):\n",
    "          # Splitting data and training RF classifer\n",
    "          X_tr, y_tr = build_pairs_training(X_train)\n",
    "          X_te, y_te =  build_pairs_testing(X_test)\n",
    "          reg = LogisticRegression(max_iter = 4000)\n",
    "          #print(X_tr.shape)\n",
    "          #print(y_tr.shape)\n",
    "          #print(X_te.shape)\n",
    "          #print(y_te.shape)\n",
    "          reg.fit(X_tr, y_tr)\n",
    "          accs[i] = reg.score(X_te, y_te)\n",
    "      print('Mean accuracy: {:0.4f}'.format(accs.mean()))\n",
    "      print('Standard deviation: {:0.4f}'.format(accs.std()))\n",
    "\n",
    "def MLP(X_train,X_test,n_trials = 100):\n",
    "      accs = np.zeros((n_trials,))\n",
    "\n",
    "      for i in range(n_trials):\n",
    "          # Splitting data and training RF classifer\n",
    "          X_tr, y_tr = build_pairs_training(X_train)\n",
    "          X_te, y_te =  build_pairs_testing(X_test)\n",
    "          clf = MLPClassifier(max_iter=300)\n",
    "          clf.fit(X_tr, y_tr)\n",
    "          accs[i] = clf.score(X_te, y_te)\n",
    "      print('Mean accuracy: {:0.4f}'.format(accs.mean()))\n",
    "      print('Standard deviation: {:0.4f}'.format(accs.std()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean accuracy: 0.4969\n",
      "Standard deviation: 0.0316\n"
     ]
    }
   ],
   "source": [
    "#RF(X_train,X_test)\n",
    "LR(X_train,X_test)\n",
    "#MLP(X_train,X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distance Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rKVGOnQyuJm0"
   },
   "outputs": [],
   "source": [
    "from numpy.linalg import norm\n",
    "distance_to_ = []\n",
    "for i in range(0,X_test.shape[0]):\n",
    "  sublist = []\n",
    "  for j in range(0,X_test.shape[0]):\n",
    "    labels = tuple([test_dataset[i][1],test_dataset[j][1]])\n",
    "    sublist.append(tuple([norm(X_test[i]-X_test[j]),labels]))\n",
    "  distance_to_.append(sublist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tPSmBFmDu1m6"
   },
   "outputs": [],
   "source": [
    "x_neg = []\n",
    "x_pos = []\n",
    "x_arr_neg = np.asarray([0]*len(test_dataset))\n",
    "x_arr_pos = np.asarray([0]*len(test_dataset))\n",
    "x_arr_neg_list = []\n",
    "x_arr_pos_list = []\n",
    "x_arr_labels_list = []\n",
    "x_arr_labels_list_n = []\n",
    "\n",
    "for i in range(0,int(len(distance_to_)/2)):\n",
    "  x_n_ = []\n",
    "  x_p_ = []\n",
    "  x_p_labels = []\n",
    "  x_n_labels = []\n",
    "  x_n_labels_raw = []\n",
    "  for j in range(0,int(len(distance_to_)/2)):\n",
    "    if distance_to_[i*2+1][j*2][1][1] == i:\n",
    "      x_p_.append(distance_to_[i*2+1][j*2][0]) \n",
    "      x_p_labels.append(i)\n",
    "    else:\n",
    "      x_n_.append(distance_to_[i*2+1][j*2][0])\n",
    "      x_n_labels.append((i*2+1,j*2))\n",
    "      x_n_labels_raw.append((i,j))\n",
    "  x_arr_neg_ = np.asarray(x_n_)\n",
    "  x_arr_pos_ = np.asarray(x_p_)\n",
    "  x_arr_neg_list.append(x_arr_neg_)\n",
    "  #x_arr_pos = x_arr_pos + x_arr_pos_\n",
    "  x_arr_pos_list.append(x_arr_pos_)\n",
    "  x_arr_labels_list.append(x_p_labels)\n",
    "  x_arr_labels_list_n.append(x_n_labels_raw)\n",
    "  x_mean_neg = np.mean(x_arr_neg, axis=0)\n",
    "  x_mean_pos = np.mean(x_arr_pos, axis=0)\n",
    "  x_std_neg = np.std(x_arr_neg, axis=0)\n",
    "  x_std_pos = np.std(x_arr_pos, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 301
    },
    "colab_type": "code",
    "id": "P3upPrTURfRD",
    "outputId": "c06996a0-b928-4e77-c398-289bcf495faa"
   },
   "outputs": [],
   "source": [
    "import seaborn as sns, numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set()\n",
    "x = x_arr_neg_list\n",
    "x_2 =  x_arr_pos_list\n",
    "ax = sns.distplot(x,label=\"different location\")\n",
    "ax = sns.distplot(x_2,label=\"same location\")\n",
    "ax.set(xlabel='Distance', ylabel='Distribution')\n",
    "plt.title(\"Distance between tile2vec embeddings\") \n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Experiments with other models_tile2vec.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
